# RAG Pipeline Configuration

# Document Processing - LangChain Text Splitter
document_processing:
  chunk_size: 1000  # Characters per chunk
  chunk_overlap: 200  # Overlap between chunks for context
  separators: ["\n\n", "\n", ". ", " ", ""]  # Split hierarchy
  length_function: "len"  # Function to measure chunk size
  
# Vector Store Settings - ChromaDB
vector_store:
  type: "chroma"
  persist_directory: "data/vector_stores"
  collection_name: "pdf_documents"
  
  # ChromaDB specific settings
  chroma:
    anonymized_telemetry: false
    allow_reset: true
    
  # Distance metric for similarity search
  distance_metric: "cosine"  # Options: cosine, l2, ip (inner product)
  
# Retrieval Settings
retrieval:
  search_type: "similarity"  # Options: similarity, mmr (maximal marginal relevance)
  k: 4  # Number of documents to retrieve
  score_threshold: 0.7  # Minimum similarity score (0-1)
  
  # MMR settings (if using search_type: mmr)
  mmr:
    fetch_k: 20  # Number of documents to fetch before MMR
    lambda_mult: 0.5  # Diversity vs relevance (0=max diversity, 1=max relevance)
  
# RAG Chain Settings - LangChain
rag_chain:
  chain_type: "stuff"  # Options: stuff, map_reduce, refine, map_rerank
  return_source_documents: true  # Include source chunks in response
  verbose: false  # Enable for debugging
  
  # Prompt template settings
  prompt:
    include_context: true
    include_question: true
    max_context_length: 4000  # Maximum characters from retrieved docs
